\subsection{Preliminaries}

\todo{Merge section with background chapter}

%% AK: the below is not needed as it is captured by DDifuse.
%\subsubsection{Restrictions imposed on the environment}
%
%We assume that the execution satisfies the following conditions:
%  (a) At each slot $\slot_j$, the environment $\env$  activates
%  all honest parties.
%  (b) The adversary is activated at least as the last entity in each $\slot_j$
%  (as well as during all adversarial party activations and invocations
%  from the ideal functionalities as prescribed).
  %(c) If a stakeholder does not fetch in a certain slot
  %the messages written to its incoming string from the diffuse functionality
  %they are flushed.

Clearly, the above model is by itself too strong to allow us to prove  any meaningful security
guarantees for the executed protocol without further restrictions (as it, for
example, does not prevent the adversary from corrupting all the participating
parties). Therefore, in what follows, we will consider such additional
assumptions, and will only
provide security guarantees as long as such assumptions are satisfied.
These assumptions will be specific to the protocol in consideration, and will be an
explicit part of our statements.\footnote{As an example, we will be assuming that a
majority of a certain pool of stake is controlled by uncorrupted parties.}
%Formally, such assumptions can be captured by putting restrictions on the class
%of admissible environments~$\env$, as done in previous
%works~\cite{C:KRDO17,EC:DGKR18}.


%It is easy to see that the model above confers such sweeping power on
%the adversary that one cannot establish any significant guarantees on
%protocols of interest.  It is thus important to restrict the
%environment suitably (taking into account the details of the protocol) so
%that we may be able to argue security.
%We require that in every slot, the adversary does not control more than $50\%$
%of the stake in the view of any honest stakeholder.
%This transaction data, including the required signatures by each stakeholder, is obtained by the environment as specified in the protocol.
%If this is violated, an event $\mathsf{Bad}^{\frac{1}{2}}$ becomes true for the
%given execution.
%When the environment spawns a new stakeholder by sending message $(\mathsf{Create},U,\chain)$ to the Key and Transaction functionality,
%the initial local chain $\chain$ can be the chain of any honest stakeholder even in the case of ``lazy honest'' stakeholders as described in Appendix~\ref{app:lazy},
%without requiring this stakeholder to have been online in the past slot as in~\cite{C:KRDO17}.
%Finally,
%we note that in all our proofs, whenever we say that a property $Q$ holds with high
%probability over all executions,
%we will in fact argue that $Q \lor {\sf Bad}^{\frac{1}{2}}$ holds with high probability
%over all executions. This  captures the fact that we exclude environments and adversaries
%that trigger ${\sf Bad}^{\frac{1}{2}}$ with non-negligible probability.




\subsection{Underlying Proof-of-Stake Protocols}
\label{sec:ouroboros}
\label{sec:pos}

For conciseness we present our construction on a generic PoS protoocol
 based on  Ouroboros PoS \cite{C:KRDO17}. As we outline
in Appendix~\ref{app:other}, our construction can  be easily adapted to other
provably secure proof-of-stake protocols: Ouroboros
Praos~\cite{EC:DGKR18}, Ouroboros Genesis~\cite{genesis}, Snow
White~\cite{DBLP:journals/iacr/BentovPS16a}, and Algorand~\cite{algorand}.
