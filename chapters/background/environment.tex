\subsection{The Environment}\label{sec:env}

We will begin with a simple model and make it successively more nuanced until it
is sufficiently sophisticated to satisfactorily capture the real world. First,
we describe the simple environment in which the network is \emph{synchronous}
and the execution is with \emph{static difficulty}. We then relax the synchrony
assumption by introducing a $\Delta$-bounded delay network. Subsequently, we
relax the static assumption by introducing executions of
\emph{variable difficulty} in which populations can be adversarially evolved.
Last, we give the adversary even more power by allowing her to adaptively
corrupt parties of her choice. We now introduce these models in order.

\glsxtrnewsymbol[description={number of parties}]{n}{n}\glsadd{n}
\glsxtrnewsymbol[description={number of adversarial parties}]{t}{t}\glsadd{t}
In our setting, we will study executions of protocols in which some parties
are \emph{honest} while others are \emph{adversarial}. All the honest parties
typically run the same code termed \emph{the honest protocol} (which is the
protocol we will design), while the adversary can run any code she wishes, but
is bounded by polynomial time bounds. Both the honest parties and the adversary
are probabilistic Turing Machines. As we are working in distributed settings,
our protocols will be long-lived and involve multiple parties running
simultaneously and communicating over the network while maintaining local state.
Among the parties in our execution, we will denote by $n$ the total number of
parties and with $t$ the number of parties that are adversarial. To strengthen
our adversary, we assume all the adversarial parties \emph{collude} and are
controlled by a single adversary. The situation where multiple adversaries are
not colluding is also captured by our stronger model (this can be captured by a
single adversary which simulates the multiple non-colluding adversaries).

\glsxtrnewsymbol[description={environment}]{environment}{$\mathcal{Z}$}\glsadd{environment}
To model the distributed setting, we must speak of executions concretely.
Towards this purpose, we conjure an \emph{environment} $\mathcal{Z}$
\index{Environment}\index{$\mathcal{Z}$} which is an
Interactive Turing Machine~\cite{interactive-tm} (ITMs) \index{Interactive
Turing Machine (ITM)} and is responsible for
orchestrating the whole execution. An Interactive Turing Machine is a Turing
Machine which models interactive computation by employing additional input and
output tapes that can be written to by external machines. The machine can decide
to pause computation by entering a special state and its computation is resumed
by writing to its input tape.

\glsxtrnewsymbol[description={honest protocol}]{upper-pi}{$\Pi$}\glsadd{upper-pi}
The environment spawns $n - t$ honest parties running the honest protocol $\Pi$ as
$n$ different Interactive Turing Machines. The environment also spawns one
adversarial Interactive Turing Machine $\mathcal{A}$. The honest parties and the
adversary can pass messages to the environment and receive messages from it by
writing and/or reading from their interactive tapes. The environment takes as
input the security parameter $1^\lambda$ and functions as an operating system
scheduler to activate the honest parties and the adversary according to some
schedule. The environment halts after polynomial time. The Interactive Turing
Machine model is equivalent to having the environment faithfully simulate the
execution of the honest parties and the adversary and correctly maintaining
their state across pausing and resumption.

\glsxtrnewsymbol[description={transcript of execution}]{view}{$\view_{\Pi,\mathcal{A}}^{n,t}$}\glsadd{view}
We study an execution by observing its transcript (the messages exchanged by the
parties) as well as the internal state of the parties throughout the execution.
This transcript, which we will denote $\view_{\Pi,\mathcal{A}}^{n,t}$, is a
random variable which is a function of the coins of the probabilistic
Interactive Turing Machines that form the execution, namely the environment
itself, the adversary, the honest parties, and the Random Oracle. We remark that
this treatment is similar to the setting of Universal Composability~\cite{uc}.
Despite the similarities on the surface, we do not fully employ it and neither
are our protocols composable, nor are our security proofs simulation-based. On
the contrary, we use a direct property-based approach in our proofs instead of
employing universally composable functionalities.

A skeleton for the environment is illustrated in Algorithm~\ref{alg.environment}.

\input{chapters/background/algorithms/alg.environment}

At the beginning of the execution, all the ITMs are booted by invoking their
constructors. The environment spins up $n - t$ honest machines that run
the protocol $\Pi$ and one adversarial machine that runs the protocol
$\mathcal{A}$ and represents the $t$ adversarial parties. These machines are
stateful, and so we denote the respective ITM (which can be paused and resumed)
by $P_i$ for the honest parties (running protocol $\Pi$) and by $A$ for the
adversary (running protocol $\mathcal{A}$). The machines are given time
polynomial in $\lambda$ by invoking their constructors with the parameter
$1^\lambda$. During construction, the adversary
learns of the number of honest parties $n - t$ and adversarial parties $t$.
Importantly, the honest parties do not have this privilege. We
call this setting \emph{permissionless setting}\index{Permissionless} (also
known as the \emph{anonymous byzantine} or \emph{open setting}), because honest
parties are not informed of each others' identities nor their count. Contrary to
our treatment throughout this thesis, there also exists a
\emph{permissioned}~\cite{consensus-sok} setting in the blockchain literature.
In that setting, the $n$ nodes are given authenticated channels between each
other and the quantity $n$ is known to all parties. We will not make this
assumption here. The fact that we are working in the permissionless setting
gives rise to the \emph{decentralized}\index{Decentralized} title of this
thesis.

\glsxtrnewsymbol[description={round}]{round}{$r$}\glsadd{round}
Time is quantized into discrete \emph{rounds}~\cite{backbone}\index{Round}\index{Slot} (or \emph{slots}~\cite{ouroboros}) numbered $r = 1, 2, 3, \cdots$.
The
environment contains a main loop which executes one iteration per round $r$ for
a total polynomial number of rounds $p(\lambda)$. During
every round, it first activates every honest party $P_i$ by invoking its
\textsf{execute} method. Subsequently, at the end of
the round, it actives the adversary $A$. The fact that the adversary is activated at
the end of every round is an advantage for the adversary. We call such an
adversary a \emph{rushing adversary}\index{Rushing Adversary}, because it can use its computational power
for the round after it has observed what the honest parties have done during the
same round. Both the honest party and the adversary can know the index of the
current round by counting how many times they have been activated so far in
their persistent state. Because both the honest parties and the
adversary are PPT machines, they will run for polynomial time every time they
are activated. Additionally, we assume $n$ is polynomial, thus ensuring the
total execution time is polynomial.

\subsection{The Network}

When an honest party is activated, it is given messages from the network to
\emph{read}, which are written to a special location within its input tape by
the environment. Here, we denote the network messages received by party $i$ as
$\overline{C}[i]$ and pass them as input to the \textsf{execute} method. The
party can then \emph{write} messages to the network during the round, which we
denote by the \textsf{execute} method returning a value. We say that such
messages are \emph{diffused}\index{Diffuse} to the network and we will use
the \textsf{Diffuse} notation within the implementation of honest protocols to
signify that a message needs to be diffused to the rest of the parties. At the end of the
round, the adversary can see all the messages $C$ that have been diffused by the
honest parties during the same round. The adversary can then decide what will
appear in the network tape of every honest party at the beginning of the next
round by outputting an array $\overline{C}$ that contains a list of messages
$\overline{C}[i]$ for every party $i$. The adversary can reorder the messages and
insert as many of her own as she wishes. That is, it is possible that
$\overline{C}[i]$ will contain more messages than $\overline{C}$ and that the
messages in $\overline{C}[i]$ will appear in a different order than in
$\overline{C}$. As such, communication is not authenticated.

However, she must ensure that all messages diffused by any honest party
during the previous round appear in the network tape of every other honest party
at the beginning of the next round. This is ensured by the assertion in Line~\ref{alg.environment.connectivity}. This means that no messages can be dropped
by the adversary. This \emph{connectivity} assumption is equivalent to assuming
that each honest party is not \emph{eclipsed}~\cite{eclipse,eclipse-ethereum}\index{Eclipse}
from the rest of the network. In practice, this is achieved by ensuring that
every honest party is connected to every other honest party through some path,
although not necessarily directly. Practical peer-to-peer protocols use
gossiping~\cite{gossip}\index{Gossip} to ensure messages reach every participant of the network. The network
model abstracts out such details and treats a round as the unit time which is
needed for a message to reach from every honest party to every other honest
party.

Crucially, because the adversary can reorder messages and inject as many
additional messages as she pleases, she is a
\emph{sybil adversary}~\cite{sybil}\index{Sybil Attack}. This means that the adversary can fake
multiple identities and pretend to produce messages by multiple parties,
potentially more than $t$. It will be the job of our honest protocol to produce
a \emph{sybil resilient} mechanism in which such attacks have no impact on the
protocol's security. Furthermore, the adversary can \emph{split} the view of the
honest parties because she can communicate different messages to different
honest parties and have $C[i] \neq C[j]$ for $i \neq j$ on the same round. For example, the order in which messages are delivered can be
different for every honest party and the adversary may inject different messages
of her own for every honest party.

The requirement that messages diffused at the end of one round are delivered at
the beginning of the next is the \emph{synchronous model}\index{Synchronous}. A
large part of our analysis will be made there.

In addition to the details specified in the environment of
Algorithm~\ref{alg.environment}, we allow the honest parties to receive
auxiliary \emph{input}, distinguished from the network tape. This input is
adversarially chosen and can influence the decisions of the honest parties. Once
these notions have been defined, such input will correspond to
\emph{transactions} that the honest parties will wish to include in their
blockchains.

\input{chapters/background/algorithms/alg.delta-environment}

\glsxtrnewsymbol[description={network delay}]{delay}{$\Delta$}\glsadd{delay}
A relaxation of the synchronous model is the $\Delta$-bounded
delay\index{$\Delta$-bounded Delay} model and is illustrated in Algorithm~\ref{alg.delta-environment}. In this model, the adversary may
delay messages up to $\Delta$ rounds before finally delivering them. Any message
diffused by any honest party at round $r$ must appear in the network tapes of
all other honest parties prior to round $r + \Delta$. This $\Delta$ is unknown
to the honest parties, although the security of the protocol requires that
$\Delta$, together with other protocol parameters, satisfies a number of
conditions. As such, this model stands between the \emph{synchronous} setting
(where $\Delta$ is known by all honest parties beforehand or, equivalently,
$\Delta = 1$) and the \emph{semi-synchronous} setting (where $\Delta$ is
completely unknown) in that, while $\Delta$ itself is unknown, it is governed by
equations which express a trade-off between $\Delta$ and other quantities, and
these equations are known.

Chapters~\ref{chapter:work},
\ref{chapter:stake}, \ref{chapter:superlight}, \ref{chapter:sidechains} are
explored in the synchronous model. We extend our protocol to the $\Delta$-bounded
delay model in Chapter~\ref{chapter:variable}.

\subsection{Evolving Population}
So far, we have defined the environment for executions in which $n$ and $t$ are
fixed throughout the execution. We call this setting the
\emph{static difficulty}\index{Static Difficulty}~\cite{backbone,backbone-new}
setting. The model can be relaxed to allow the population to evolve with time.
This gives rise to the
\emph{variable difficulty}\index{Variable Difficulty}~\cite{varbackbone}
model.
Instead of two fixed values $n$ and $t$, we instead consider two
\emph{sequences} of values
$\{n_r\}_{r \in [p(\lambda)]}$ and $\{t_r\}_{r \in [p(\lambda)]}$.
At round $r$, when $n_r - t_r < n_{r-1} - t_{r-1}$, the number of honest
parties has decreased and $(n_{r-1} - t_{r-1}) - (n_r - t_r)$ honest ITM
instances are killed by the environment. The choice of which instances will be
killed is made by the adversary. When
$n_r - t_r > n_{r-1} - t_{r-1}$, the number of honest parties has increased and
$(n_r - t_r) - (n_{r-1} - t_{r-1})$ new honest instances are spawned up by
cloning the state of some existing honest instances. The choice of which
instances to clone is made by the adversary. An increasing or decreasing $t_r$
does not affect the spawned instances. Finally, the choice of how $n_r$
and $t_r$ evolve is made \emph{adaptively} by the adversary~\cite{varbackbone-new}
based on the execution so far.

\input{chapters/background/algorithms/alg.var-environment}

In the variable difficulty setting, we will concern ourselves with protocols in
which the population evolution is gradual and observes certain
bounds~\cite{varbackbone}.

\glsxtrnewsymbol[description={bounded population evolution parameter}]{gamma}{$\gamma$}\glsadd{gamma}
\begin{definition}[Bounded demographic]
  For $\gamma \in \mathbb{R}^+$, a population sequence
  $(n_r)_{r\in\mathbb{N}}$ is called \emph{$(\gamma, s)$-respecting} if for any
  $S$ of at most $s$ consecutive rounds,
  $\max_{r \in S}n_r \leq \gamma\cdot \min_{r \in S}n_r$.
\end{definition}

\subsection{Adaptive Corruption}
\label{sec:prelim-corr}

The environment already allows the adversary to control a certain number
of parties. If the identities of these parties are fixed at the beginning of
the execution, as presented before, we speak of
\emph{static corruption}\index{Static Corruption}. This is sufficient to treat
Proof-of-Work blockchains (Chapters~\ref{chapter:work}, \ref{chapter:variable}
and \ref{chapter:superlight}), but a more nuanced model is required for
Proof-of-Stake (Chapters~\ref{chapter:stake} and \ref{chapter:sidechains}).
In Proof-of-Stake protocols, just \emph{which} parties are
corrupted will be significant, because the corrupted parties will be maintaining
important secrets in their local state (namely, keys controlling money). As
such, it is not sufficient to capture the notion that $t$ of $n$ parties are
corrupted, but the model will require the adversary to specify which parties are
corrupted. At the point of corruption, the honest party $\party_i$ relinquishes
its entire state to the adversary and is killed, while $t$ is incremented by
$1$. In this more detailed model, the adversary first attempts to corrupt an
honest party $P_i$ by requesting to do so from the environment. This permission
is granted after a certain delay of $\cordelay$ rounds, where $\cordelay$ is a
parameter of our model (and can be different from the network delay $\Delta$).
In particular, if $\cordelay=0$ we talk about \emph{fully adaptive
corruptions}\index{Fully Adaptive Corruption} and the corruption is immediate.
The model with $\cordelay>0$ is referred to as allowing \emph{semi-adaptive
corruptions}\index{Semi-Adaptive Corruption}.
